{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0710 16:15:06.487787 140554902615872 secure_random.py:22] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.14.1-dev20190517). Fix this by compiling custom ops.\n",
      "W0710 16:15:06.505488 140554902615872 deprecation_wrapper.py:119] From /home/ayush/anaconda3/lib/python3.7/site-packages/tf_encrypted/session.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Building a federated learning model\n",
    "\n",
    "#Importing the libraries\n",
    "import torch as th\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Dataset\n",
    "data = th.tensor([[1.,1], [0,1], [1,0], [0,0]], requires_grad=True)\n",
    "target = th.tensor([[1.], [1], [0], [0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the workers\n",
    "bob = sy.VirtualWorker(hook, id='bob')\n",
    "alice = sy.VirtualWorker(hook, id='alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending data and target to workers\n",
    "bob_data = data[0:2].send(bob)\n",
    "bob_target = target[0:2].send(bob)\n",
    "alice_data = data[2:4].send(alice)\n",
    "alice_target = target[2:4].send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a model\n",
    "model = nn.Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob loss :  tensor(2.2542)\n",
      "Alice loss :  tensor(0.2750)\n",
      "Bob loss :  tensor(1.5568)\n",
      "Alice loss :  tensor(0.2130)\n",
      "Bob loss :  tensor(1.1299)\n",
      "Alice loss :  tensor(0.2072)\n",
      "Bob loss :  tensor(0.8590)\n",
      "Alice loss :  tensor(0.2187)\n",
      "Bob loss :  tensor(0.6799)\n",
      "Alice loss :  tensor(0.2309)\n",
      "Bob loss :  tensor(0.5564)\n",
      "Alice loss :  tensor(0.2380)\n",
      "Bob loss :  tensor(0.4673)\n",
      "Alice loss :  tensor(0.2390)\n",
      "Bob loss :  tensor(0.4004)\n",
      "Alice loss :  tensor(0.2347)\n",
      "Bob loss :  tensor(0.3482)\n",
      "Alice loss :  tensor(0.2263)\n",
      "Bob loss :  tensor(0.3062)\n",
      "Alice loss :  tensor(0.2153)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    bob_model = model.copy().send(bob)\n",
    "    alice_model = model.copy().send(alice)\n",
    "    \n",
    "    bob_optim = optim.SGD(bob_model.parameters(), lr = 0.01)\n",
    "    alice_optim = optim.SGD(alice_model.parameters(), lr = 0.01)\n",
    "    \n",
    "    for i in range(5):\n",
    "        #Train bob model\n",
    "        bob_optim.zero_grad()\n",
    "\n",
    "        bob_preds = bob_model(bob_data)\n",
    "        bob_loss = ((bob_preds - bob_target)**2).sum()\n",
    "        bob_loss.backward()\n",
    "        bob_optim.step()\n",
    "\n",
    "        bob_loss = bob_loss.get().data\n",
    "\n",
    "        #Train alice model\n",
    "        alice_optim.zero_grad()\n",
    "\n",
    "        alice_preds = alice_model(alice_data)\n",
    "        alice_loss = ((alice_preds - alice_target)**2).sum()\n",
    "        alice_loss.backward()\n",
    "        alice_optim.step()\n",
    "\n",
    "        alice_loss = alice_loss.get().data\n",
    "    \n",
    "    print(\"Bob loss : \", bob_loss, \"Alice loss : \", alice_loss)\n",
    "    \n",
    "    alice_model.move(bob)\n",
    "    \n",
    "    with th.no_grad():\n",
    "        model.weight.set_(((alice_model.weight.data + bob_model.weight.data)/2).get())\n",
    "        model.bias.set_(((alice_model.bias.data + bob_model.bias.data)/2).get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(data)\n",
    "loss =  ((preds - target)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9370],\n",
      "        [ 0.3840],\n",
      "        [ 0.5193],\n",
      "        [-0.0336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]], requires_grad=True)\n",
      "tensor(0.6543, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
