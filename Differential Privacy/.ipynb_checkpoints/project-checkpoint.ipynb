{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 23:50:33.599641 140444323645248 secure_random.py:22] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.14.1-dev20190517). Fix this by compiling custom ops.\n",
      "W0627 23:50:33.616016 140444323645248 deprecation_wrapper.py:119] From /home/ayush/anaconda3/lib/python3.7/site-packages/tf_encrypted/session.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "from syft.frameworks.torch.differential_privacy import pate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of teachers :  100\n",
      "Length of data in teacher set :  600\n",
      "Length of student set :  9000\n",
      "Length of test set :  1000\n"
     ]
    }
   ],
   "source": [
    "num_teacher = 100\n",
    "len_teacher_set = len(trainset)//num_teacher\n",
    "\n",
    "teacher_set = [torch.utils.data.Subset(trainset, list(range(i * len_teacher_set, (i+1) * len_teacher_set))) for i in range(num_teacher)]\n",
    "student_set = torch.utils.data.Subset(testset, list(range(int(len(testset) * 0.9))))\n",
    "test_set = torch.utils.data.Subset(testset, list(range(int(len(testset) * 0.9), len(testset))))\n",
    "\n",
    "print(\"Number of teachers : \", num_teacher)\n",
    "print(\"Length of data in teacher set : \", len_teacher_set)\n",
    "print(\"Length of student set : \", len(student_set))\n",
    "print(\"Length of test set : \", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.log_softmax(self.fc2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "teachers = [Model().to(device) for _ in range(num_teacher)]\n",
    "student = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacherloader = [torch.utils.data.DataLoader(data, batch_size=60, shuffle = True, drop_last=True) for data in teacher_set]\n",
    "teacheroptim = [optim.SGD(teacher.parameters(), lr = 0.01, momentum = 0.5) for teacher in teachers]\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in teachers:\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average losses :  [2.2995219469070434, 2.305666947364807, 2.29987108707428, 2.302030611038208, 2.306314539909363, 2.3153051376342773, 2.3184807538986205, 2.317122983932495, 2.311061978340149, 2.3035390615463256, 2.3155261278152466, 2.3142776250839234, 2.319117045402527, 2.3171235084533692, 2.3179646253585817, 2.3066146850585936, 2.3072688817977904, 2.306585669517517, 2.2924521207809447, 2.3174992561340333, 2.310452961921692, 2.3078145742416383, 2.3044384956359862, 2.309654426574707, 2.3101694107055666, 2.3078023910522463, 2.3066566705703737, 2.297309970855713, 2.3204730272293093, 2.3042556047439575, 2.319070076942444, 2.3130789518356325, 2.3139078855514525, 2.3053664684295656, 2.3030473709106447, 2.3131420612335205, 2.31833131313324, 2.3091835260391234, 2.303018665313721, 2.304009747505188, 2.3160953521728516, 2.3063392639160156, 2.315123105049133, 2.3172696113586424, 2.3124369859695433, 2.3058178186416627, 2.306938910484314, 2.316112756729126, 2.3174724102020265, 2.3147616147994996, 2.31613028049469, 2.308351469039917, 2.3198578119277955, 2.313240885734558, 2.308608961105347, 2.3134198904037477, 2.3103614807128907, 2.3071921348571776, 2.301132249832153, 2.296850156784058, 2.3109697103500366, 2.303986668586731, 2.3117833375930785, 2.3087481021881104, 2.3068106174468994, 2.321467137336731, 2.314565134048462, 2.3136858701705934, 2.3026101350784303, 2.3091137170791627, 2.315182113647461, 2.308943819999695, 2.3098733901977537, 2.307496929168701, 2.2968822956085204, 2.2972860097885133, 2.316880798339844, 2.317217779159546, 2.3172155380249024, 2.3177719354629516, 2.308870482444763, 2.3148380756378173, 2.2927322387695312, 2.316814589500427, 2.3055513858795167, 2.3019142150878906, 2.313284158706665, 2.3053164005279543, 2.3057619094848634, 2.315149116516113, 2.3145781993865966, 2.3259437561035154, 2.3070129632949827, 2.328459692001343, 2.312828469276428, 2.303082275390625, 2.320425772666931, 2.3115436315536497, 2.3068183422088624, 2.3107702255249025]\n",
      " Average accuracies :  [0.09166666666666666, 0.12166666666666667, 0.11, 0.10833333333333334, 0.11333333333333333, 0.10833333333333334, 0.10166666666666667, 0.09666666666666666, 0.09833333333333333, 0.1, 0.09333333333333334, 0.08833333333333333, 0.08, 0.08666666666666667, 0.06833333333333333, 0.13666666666666666, 0.085, 0.11166666666666666, 0.125, 0.10166666666666667, 0.10333333333333333, 0.095, 0.12833333333333333, 0.10833333333333334, 0.10166666666666667, 0.1, 0.125, 0.12333333333333334, 0.08666666666666667, 0.11833333333333333, 0.10166666666666667, 0.12333333333333334, 0.10166666666666667, 0.12, 0.09666666666666666, 0.09833333333333333, 0.09166666666666666, 0.115, 0.11666666666666667, 0.10333333333333333, 0.10166666666666667, 0.11833333333333333, 0.09666666666666666, 0.09166666666666666, 0.1, 0.09666666666666666, 0.11, 0.12166666666666667, 0.08333333333333333, 0.10833333333333334, 0.095, 0.08666666666666667, 0.09, 0.11333333333333333, 0.08833333333333333, 0.1, 0.12, 0.12, 0.11333333333333333, 0.14333333333333334, 0.06333333333333334, 0.13, 0.10666666666666667, 0.11333333333333333, 0.10833333333333334, 0.10666666666666667, 0.09, 0.1, 0.10166666666666667, 0.11833333333333333, 0.09166666666666666, 0.09666666666666666, 0.115, 0.095, 0.11833333333333333, 0.09333333333333334, 0.09666666666666666, 0.07166666666666667, 0.08833333333333333, 0.095, 0.10833333333333334, 0.09166666666666666, 0.135, 0.085, 0.11166666666666666, 0.11333333333333333, 0.09166666666666666, 0.10333333333333333, 0.09666666666666666, 0.10166666666666667, 0.09666666666666666, 0.09, 0.11166666666666666, 0.11833333333333333, 0.11333333333333333, 0.08166666666666667, 0.06666666666666667, 0.12666666666666668, 0.10833333333333334, 0.09666666666666666]\n",
      "Epoch  2  ...\n",
      " Average losses :  [2.293373203277588, 2.3023590087890624, 2.300520086288452, 2.300794315338135, 2.2933552503585815, 2.3090317249298096, 2.3008625745773315, 2.3039761066436766, 2.3095178604125977, 2.291145181655884, 2.3078935623168944, 2.3073415517807008, 2.3086172342300415, 2.3089733839035036, 2.313677716255188, 2.3053043842315675, 2.294425392150879, 2.2979294300079345, 2.295880126953125, 2.3139786958694457, 2.2943985223770142, 2.297798252105713, 2.302890253067017, 2.2951341390609743, 2.310745692253113, 2.3048173666000364, 2.297450637817383, 2.2930267572402956, 2.303901767730713, 2.2950248241424562, 2.3098424673080444, 2.3019088983535765, 2.310095024108887, 2.299614667892456, 2.29543559551239, 2.3107566356658937, 2.3037283182144166, 2.2982058763504027, 2.299802565574646, 2.2962576389312743, 2.3098472595214843, 2.3057451963424684, 2.306366467475891, 2.305003786087036, 2.303391432762146, 2.297533369064331, 2.305330991744995, 2.303485798835754, 2.304326033592224, 2.306767702102661, 2.3048641443252564, 2.3044026136398315, 2.3044649362564087, 2.3020697593688966, 2.290887475013733, 2.303995156288147, 2.3073134899139403, 2.2964616298675535, 2.300414037704468, 2.29410183429718, 2.3042489290237427, 2.301365375518799, 2.298038148880005, 2.301169753074646, 2.298948311805725, 2.304035711288452, 2.307523274421692, 2.310441517829895, 2.3019478797912596, 2.2963889598846436, 2.3109156847000123, 2.305080771446228, 2.3016133308410645, 2.293449306488037, 2.291561818122864, 2.2949456930160523, 2.304283332824707, 2.3019150733947753, 2.303105282783508, 2.3097081899642946, 2.293650221824646, 2.2942914247512816, 2.2924543619155884, 2.3030673027038575, 2.298283505439758, 2.30270733833313, 2.3144591808319093, 2.2979065656661986, 2.2939050436019897, 2.314268970489502, 2.307836580276489, 2.3134106397628784, 2.292577934265137, 2.3147475481033326, 2.294734811782837, 2.305397605895996, 2.3062813758850096, 2.309213876724243, 2.302946424484253, 2.305595064163208]\n",
      " Average accuracies :  [0.13833333333333334, 0.11333333333333333, 0.11333333333333333, 0.12333333333333334, 0.13166666666666665, 0.11333333333333333, 0.11, 0.1, 0.08666666666666667, 0.11833333333333333, 0.09166666666666666, 0.095, 0.08, 0.10166666666666667, 0.08666666666666667, 0.11666666666666667, 0.10666666666666667, 0.13, 0.13166666666666665, 0.09166666666666666, 0.11333333333333333, 0.09833333333333333, 0.135, 0.12833333333333333, 0.105, 0.09, 0.15166666666666667, 0.155, 0.105, 0.12833333333333333, 0.1, 0.14, 0.105, 0.095, 0.105, 0.09333333333333334, 0.11, 0.11333333333333333, 0.11833333333333333, 0.13166666666666665, 0.11833333333333333, 0.11833333333333333, 0.125, 0.10166666666666667, 0.11, 0.105, 0.10333333333333333, 0.12833333333333333, 0.10333333333333333, 0.12166666666666667, 0.12333333333333334, 0.12166666666666667, 0.11, 0.11, 0.10666666666666667, 0.11, 0.12833333333333333, 0.12333333333333334, 0.125, 0.11666666666666667, 0.07, 0.12833333333333333, 0.1, 0.11, 0.15166666666666667, 0.13, 0.1, 0.08666666666666667, 0.11333333333333333, 0.13, 0.06833333333333333, 0.09333333333333334, 0.12166666666666667, 0.13666666666666666, 0.15333333333333332, 0.10166666666666667, 0.115, 0.09833333333333333, 0.11833333333333333, 0.10833333333333334, 0.13333333333333333, 0.115, 0.145, 0.12333333333333334, 0.11333333333333333, 0.125, 0.09166666666666666, 0.09, 0.115, 0.07333333333333333, 0.10833333333333334, 0.09333333333333334, 0.12166666666666667, 0.09, 0.145, 0.11166666666666666, 0.08166666666666667, 0.11833333333333333, 0.14666666666666667, 0.09166666666666666]\n",
      "Epoch  3  ...\n",
      " Average losses :  [2.2949948072433473, 2.2908485174179076, 2.297057557106018, 2.2945776700973513, 2.2861806869506838, 2.3084465980529787, 2.293650269508362, 2.2994794845581055, 2.3081664562225344, 2.2924535512924193, 2.3014893531799316, 2.3031963109970093, 2.3050745487213136, 2.2905842065811157, 2.3017829418182374, 2.2953571319580077, 2.2936689138412474, 2.283943843841553, 2.2915525436401367, 2.303546595573425, 2.292407202720642, 2.2910550594329835, 2.2980196475982666, 2.292679953575134, 2.3057428121566774, 2.2970389842987062, 2.2940320491790773, 2.2825072050094604, 2.299625062942505, 2.288335752487183, 2.302791404724121, 2.293832612037659, 2.299805164337158, 2.2945764780044557, 2.2883453607559203, 2.297949457168579, 2.2870130062103273, 2.2907416820526123, 2.2910308837890625, 2.299817419052124, 2.3012341260910034, 2.29766526222229, 2.2843648195266724, 2.300346255302429, 2.2983513832092286, 2.2946554899215696, 2.296220302581787, 2.2969677209854127, 2.301121950149536, 2.3005340099334717, 2.3062069177627564, 2.29731605052948, 2.293214464187622, 2.2883177995681763, 2.2864896774291994, 2.2904874086380005, 2.299831914901733, 2.299902844429016, 2.288883399963379, 2.2861785173416136, 2.301097559928894, 2.300592565536499, 2.296599507331848, 2.2957070589065554, 2.285328435897827, 2.2970064878463745, 2.295370411872864, 2.306756925582886, 2.2912359476089477, 2.2963992834091185, 2.3022458076477053, 2.3021570682525634, 2.3024051427841186, 2.302599620819092, 2.283302164077759, 2.285933780670166, 2.2948657512664794, 2.299941897392273, 2.304983901977539, 2.3040591955184935, 2.2856441020965574, 2.2977864027023314, 2.2910956859588625, 2.2998433828353884, 2.2945909023284914, 2.287729358673096, 2.298080086708069, 2.288213682174683, 2.2823224306106566, 2.302727770805359, 2.298485279083252, 2.302820825576782, 2.287224459648132, 2.3053130388259886, 2.2931684970855715, 2.2997045278549195, 2.301993250846863, 2.301685118675232, 2.281945824623108, 2.3019653081893923]\n",
      " Average accuracies :  [0.12333333333333334, 0.14, 0.12, 0.11166666666666666, 0.15, 0.13, 0.12, 0.11333333333333333, 0.12, 0.13833333333333334, 0.10833333333333334, 0.11, 0.09, 0.12666666666666668, 0.08333333333333333, 0.13, 0.09833333333333333, 0.145, 0.12, 0.12, 0.125, 0.125, 0.16, 0.15333333333333332, 0.085, 0.11666666666666667, 0.14833333333333334, 0.14666666666666667, 0.11, 0.12333333333333334, 0.09666666666666666, 0.14166666666666666, 0.09333333333333334, 0.115, 0.10666666666666667, 0.11, 0.12666666666666668, 0.15, 0.12666666666666668, 0.11833333333333333, 0.10833333333333334, 0.13333333333333333, 0.13166666666666665, 0.105, 0.105, 0.10833333333333334, 0.10833333333333334, 0.11666666666666667, 0.105, 0.10166666666666667, 0.11833333333333333, 0.14333333333333334, 0.11666666666666667, 0.13333333333333333, 0.12, 0.12333333333333334, 0.14, 0.09833333333333333, 0.12666666666666668, 0.13833333333333334, 0.10666666666666667, 0.13166666666666665, 0.11833333333333333, 0.12333333333333334, 0.15333333333333332, 0.145, 0.12666666666666668, 0.10333333333333333, 0.13833333333333334, 0.12833333333333333, 0.13, 0.095, 0.11, 0.11166666666666666, 0.16333333333333333, 0.12, 0.11833333333333333, 0.11666666666666667, 0.12, 0.12333333333333334, 0.12, 0.10833333333333334, 0.15, 0.09166666666666666, 0.11833333333333333, 0.10333333333333333, 0.115, 0.115, 0.15666666666666668, 0.09666666666666666, 0.14, 0.115, 0.135, 0.10666666666666667, 0.13833333333333334, 0.10166666666666667, 0.095, 0.125, 0.125, 0.125]\n",
      "Epoch  4  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average losses :  [2.2878992319107057, 2.286103105545044, 2.288249111175537, 2.288210391998291, 2.284455490112305, 2.2952073574066163, 2.281778264045715, 2.2881479263305664, 2.2996309280395506, 2.2815032482147215, 2.2958001136779784, 2.2943394422531127, 2.303026056289673, 2.289693737030029, 2.2994964838027956, 2.297956609725952, 2.291089129447937, 2.2782259941101075, 2.2895596742630007, 2.3039602994918824, 2.282843065261841, 2.2914784431457518, 2.2947973251342773, 2.2900833606719972, 2.3045347929000854, 2.291913318634033, 2.289506721496582, 2.2774462938308715, 2.2954468011856077, 2.2729913234710692, 2.295777702331543, 2.2921847820281984, 2.2996872663497925, 2.293791890144348, 2.284015488624573, 2.291038751602173, 2.2778178453445435, 2.2867202758789062, 2.2798385858535766, 2.2895717144012453, 2.293033790588379, 2.289947748184204, 2.2696926832199096, 2.295727586746216, 2.2953218460083007, 2.2920624732971193, 2.289257216453552, 2.2866121530532837, 2.299182152748108, 2.2924185514450075, 2.3029207944869996, 2.2923526525497437, 2.304754614830017, 2.283031392097473, 2.2872422456741335, 2.290178990364075, 2.289173793792725, 2.2934314250946044, 2.281855034828186, 2.282533311843872, 2.2950233221054077, 2.293031644821167, 2.2868814945220945, 2.2947023630142214, 2.290204977989197, 2.2954283237457274, 2.299011206626892, 2.2941331386566164, 2.2904989957809447, 2.2924484252929687, 2.302600359916687, 2.295395112037659, 2.2954299449920654, 2.291806173324585, 2.278032636642456, 2.2867897033691404, 2.2910064697265624, 2.2939682483673094, 2.2908240079879763, 2.2996631622314454, 2.2800995111465454, 2.280131483078003, 2.2856455087661742, 2.2878792524337768, 2.2946219444274902, 2.286030125617981, 2.293340826034546, 2.287507247924805, 2.2769898414611816, 2.3046507120132445, 2.286610746383667, 2.2953880548477175, 2.276322770118713, 2.2958000898361206, 2.2802902936935423, 2.29315071105957, 2.2882038354873657, 2.2926843404769897, 2.2643359422683718, 2.294867825508118]\n",
      " Average accuracies :  [0.135, 0.14166666666666666, 0.12833333333333333, 0.115, 0.145, 0.14833333333333334, 0.15, 0.12666666666666668, 0.11166666666666666, 0.16166666666666665, 0.12333333333333334, 0.11, 0.09833333333333333, 0.13666666666666666, 0.08166666666666667, 0.11833333333333333, 0.15666666666666668, 0.14, 0.12333333333333334, 0.12, 0.125, 0.115, 0.12166666666666667, 0.135, 0.09333333333333334, 0.10333333333333333, 0.16333333333333333, 0.16833333333333333, 0.10333333333333333, 0.14666666666666667, 0.12166666666666667, 0.16666666666666666, 0.1, 0.12333333333333334, 0.135, 0.13, 0.11833333333333333, 0.14333333333333334, 0.17666666666666667, 0.11, 0.11666666666666667, 0.135, 0.17666666666666667, 0.13166666666666665, 0.12, 0.13166666666666665, 0.12833333333333333, 0.14166666666666666, 0.09, 0.11666666666666667, 0.115, 0.13, 0.10166666666666667, 0.13166666666666665, 0.14166666666666666, 0.13333333333333333, 0.16666666666666666, 0.11666666666666667, 0.13333333333333333, 0.15333333333333332, 0.09666666666666666, 0.13833333333333334, 0.13333333333333333, 0.13, 0.14166666666666666, 0.155, 0.12166666666666667, 0.12333333333333334, 0.125, 0.13166666666666665, 0.09666666666666666, 0.12666666666666668, 0.12666666666666668, 0.14833333333333334, 0.14333333333333334, 0.10333333333333333, 0.14666666666666667, 0.12333333333333334, 0.145, 0.12833333333333333, 0.13833333333333334, 0.155, 0.16833333333333333, 0.11666666666666667, 0.11833333333333333, 0.14666666666666667, 0.12666666666666668, 0.12333333333333334, 0.15666666666666668, 0.10666666666666667, 0.135, 0.13333333333333333, 0.13166666666666665, 0.12666666666666668, 0.155, 0.13, 0.11666666666666667, 0.14333333333333334, 0.155, 0.10333333333333333]\n",
      "Epoch  5  ...\n",
      " Average losses :  [2.2890227794647218, 2.284657835960388, 2.2929003477096557, 2.2840924501419066, 2.2752237558364867, 2.2880401372909547, 2.2740593433380125, 2.280706524848938, 2.296952652931213, 2.2690509080886843, 2.2911288022994993, 2.2896427154541015, 2.2929270029067994, 2.280945134162903, 2.296114921569824, 2.288581657409668, 2.2853581428527834, 2.2715247631073, 2.2673258781433105, 2.2978191137313844, 2.2848129510879516, 2.2811895608901978, 2.2844661712646483, 2.2763180255889894, 2.302594709396362, 2.2921578884124756, 2.2823235988616943, 2.2728376626968383, 2.2860828399658204, 2.2809638738632203, 2.291768217086792, 2.2894190549850464, 2.2917136907577516, 2.2931103467941285, 2.2823869466781614, 2.288534164428711, 2.280503988265991, 2.2850296974182127, 2.277506160736084, 2.2669019222259523, 2.287691569328308, 2.2782509565353393, 2.2729507207870485, 2.293698287010193, 2.295234775543213, 2.2884600162506104, 2.282944750785828, 2.2768425703048707, 2.299884057044983, 2.2843513011932375, 2.2964463949203493, 2.2875301837921143, 2.294415235519409, 2.2734025001525877, 2.2782265663146974, 2.2878252506256103, 2.2799241065979006, 2.2895611047744753, 2.2759797096252443, 2.2754340887069704, 2.295149731636047, 2.2847917795181276, 2.2798653841018677, 2.288282322883606, 2.27879593372345, 2.2803630113601683, 2.292868971824646, 2.2920533180236817, 2.2789512634277345, 2.2842840909957887, 2.3007668972015383, 2.2924872636795044, 2.289885091781616, 2.2843292951583862, 2.2770243644714356, 2.2820333003997804, 2.2793158054351808, 2.2871185779571532, 2.2848275899887085, 2.297765350341797, 2.276431369781494, 2.275336170196533, 2.2633803129196166, 2.2855196714401247, 2.2852411031723023, 2.282887840270996, 2.28460054397583, 2.2847736358642576, 2.2692362546920775, 2.293547201156616, 2.2893932104110717, 2.2903111457824705, 2.2689522981643675, 2.2926448822021483, 2.2803080797195436, 2.2902128219604494, 2.2759657382965086, 2.289860987663269, 2.2511417627334596, 2.279985809326172]\n",
      " Average accuracies :  [0.12333333333333334, 0.13666666666666666, 0.12, 0.13666666666666666, 0.19166666666666668, 0.15, 0.14666666666666667, 0.13, 0.11833333333333333, 0.15, 0.12, 0.12, 0.13, 0.145, 0.10333333333333333, 0.155, 0.14666666666666667, 0.16, 0.17333333333333334, 0.12, 0.13166666666666665, 0.14, 0.16333333333333333, 0.14833333333333334, 0.09833333333333333, 0.11, 0.205, 0.19166666666666668, 0.13333333333333333, 0.16, 0.10333333333333333, 0.14166666666666666, 0.11333333333333333, 0.10666666666666667, 0.12666666666666668, 0.135, 0.11833333333333333, 0.14, 0.165, 0.16333333333333333, 0.135, 0.14, 0.18666666666666668, 0.13666666666666666, 0.10333333333333333, 0.115, 0.12666666666666668, 0.16833333333333333, 0.105, 0.13833333333333334, 0.115, 0.125, 0.13, 0.16, 0.16166666666666665, 0.15666666666666668, 0.14, 0.11833333333333333, 0.12333333333333334, 0.13166666666666665, 0.095, 0.14166666666666666, 0.16833333333333333, 0.12833333333333333, 0.17333333333333334, 0.15333333333333332, 0.11, 0.125, 0.12666666666666668, 0.16, 0.11166666666666666, 0.13833333333333334, 0.14, 0.14666666666666667, 0.15166666666666667, 0.125, 0.15333333333333332, 0.135, 0.16333333333333333, 0.12333333333333334, 0.14666666666666667, 0.16333333333333333, 0.17666666666666667, 0.12, 0.17666666666666667, 0.13, 0.12833333333333333, 0.12166666666666667, 0.165, 0.11833333333333333, 0.13333333333333333, 0.13666666666666666, 0.16666666666666666, 0.10833333333333334, 0.14666666666666667, 0.13833333333333334, 0.12, 0.13666666666666666, 0.17333333333333334, 0.13666666666666666]\n",
      "Epoch  6  ...\n",
      " Average losses :  [2.2813781261444093, 2.2707047700881957, 2.2773252964019775, 2.282352638244629, 2.271084785461426, 2.2884784936904907, 2.266346645355225, 2.2885245084762573, 2.285801148414612, 2.2573898792266847, 2.2887513875961303, 2.283736252784729, 2.2870198249816895, 2.280516338348389, 2.293336367607117, 2.279568243026733, 2.2806058883666993, 2.2584782361984255, 2.271665668487549, 2.2897130966186525, 2.2733458995819094, 2.2814077615737913, 2.2850517988204957, 2.281043601036072, 2.295667839050293, 2.2851266145706175, 2.2817404747009276, 2.2692744016647337, 2.2889538526535036, 2.2618629693984986, 2.267509031295776, 2.2790594577789305, 2.287347936630249, 2.2882347106933594, 2.268768572807312, 2.2828845262527464, 2.270978045463562, 2.2735361099243163, 2.2668633699417113, 2.261381244659424, 2.2783929347991942, 2.2798693895339968, 2.255685067176819, 2.2843071460723876, 2.2870068311691285, 2.2773375034332277, 2.2800644874572753, 2.2799466371536257, 2.2953411102294923, 2.2861529111862184, 2.2916361570358275, 2.2884966135025024, 2.2827441930770873, 2.2685096740722654, 2.2727208375930785, 2.2777616024017333, 2.276649498939514, 2.2879534006118774, 2.2684609651565553, 2.2652312517166138, 2.283310627937317, 2.284039354324341, 2.2702683210372925, 2.283018159866333, 2.2734423637390138, 2.2831437826156615, 2.2784823179244995, 2.2848036527633666, 2.27392373085022, 2.278073024749756, 2.2948481798172, 2.284455752372742, 2.2867550611495973, 2.284760618209839, 2.2711179494857787, 2.2756453275680544, 2.259438180923462, 2.2875368356704713, 2.2728113651275637, 2.281746196746826, 2.261555886268616, 2.266401529312134, 2.2632847309112547, 2.280996799468994, 2.2836739301681517, 2.2680394649505615, 2.282252311706543, 2.2671918869018555, 2.2484952449798583, 2.2872944831848145, 2.282426381111145, 2.2829602718353272, 2.2463844537734987, 2.2924987077713013, 2.2674658060073853, 2.284462332725525, 2.276654863357544, 2.282767176628113, 2.243293213844299, 2.2714662075042726]\n",
      " Average accuracies :  [0.16666666666666666, 0.20166666666666666, 0.15833333333333333, 0.12833333333333333, 0.195, 0.15333333333333332, 0.16166666666666665, 0.12833333333333333, 0.11833333333333333, 0.17, 0.13166666666666665, 0.14333333333333334, 0.125, 0.145, 0.11833333333333333, 0.155, 0.15, 0.145, 0.14833333333333334, 0.15, 0.145, 0.14333333333333334, 0.16833333333333333, 0.14, 0.10666666666666667, 0.125, 0.175, 0.17666666666666667, 0.12833333333333333, 0.19, 0.175, 0.175, 0.12666666666666668, 0.11166666666666666, 0.14, 0.12, 0.14833333333333334, 0.14333333333333334, 0.21166666666666667, 0.155, 0.15, 0.15166666666666667, 0.19833333333333333, 0.135, 0.11333333333333333, 0.15666666666666668, 0.12, 0.18, 0.14166666666666666, 0.13166666666666665, 0.125, 0.13333333333333333, 0.14333333333333334, 0.17, 0.14, 0.155, 0.15833333333333333, 0.15666666666666668, 0.14666666666666667, 0.17, 0.13333333333333333, 0.12166666666666667, 0.18833333333333332, 0.13833333333333334, 0.19833333333333333, 0.15333333333333332, 0.14333333333333334, 0.12, 0.14833333333333334, 0.14666666666666667, 0.1, 0.13166666666666665, 0.12833333333333333, 0.16166666666666665, 0.16, 0.14666666666666667, 0.18833333333333332, 0.125, 0.13833333333333334, 0.16166666666666665, 0.15, 0.175, 0.195, 0.12333333333333334, 0.13333333333333333, 0.18166666666666667, 0.13333333333333333, 0.13833333333333334, 0.22, 0.125, 0.15, 0.12666666666666668, 0.18666666666666668, 0.14333333333333334, 0.17666666666666667, 0.13833333333333334, 0.12666666666666668, 0.165, 0.18166666666666667, 0.14]\n",
      "Epoch  7  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average losses :  [2.2851342439651487, 2.272595524787903, 2.272645950317383, 2.270553731918335, 2.2571977376937866, 2.2829313039779664, 2.2544655323028566, 2.2855082988739013, 2.284347891807556, 2.24337375164032, 2.2800102710723875, 2.277532124519348, 2.284353566169739, 2.2581329345703125, 2.2828537702560423, 2.276129698753357, 2.2692363023757935, 2.250962495803833, 2.261930751800537, 2.279922866821289, 2.2736698627471923, 2.2716723918914794, 2.2747774600982664, 2.255029535293579, 2.292940044403076, 2.2748756408691406, 2.275331664085388, 2.2606488466262817, 2.2813384771347045, 2.249269127845764, 2.27335467338562, 2.281207633018494, 2.2908272743225098, 2.2785287380218504, 2.2589105129241944, 2.2703941822052003, 2.263875675201416, 2.2682674646377565, 2.2601881980895997, 2.2443919658660887, 2.271041202545166, 2.2711960554122923, 2.2395296812057497, 2.277860140800476, 2.28188693523407, 2.268101716041565, 2.2740428686141967, 2.2670061588287354, 2.289654493331909, 2.2726292610168457, 2.291513776779175, 2.280643177032471, 2.2826372385025024, 2.2509085893630982, 2.2624924659729, 2.275427794456482, 2.264635753631592, 2.272919034957886, 2.2512616395950316, 2.2572139739990233, 2.2840171337127684, 2.279055094718933, 2.2620574712753294, 2.2724315881729127, 2.2668173551559447, 2.2768980979919435, 2.2822492122650146, 2.2797180891036986, 2.26969735622406, 2.2702993154525757, 2.2964495420455933, 2.2779380559921263, 2.281567192077637, 2.2687942504882814, 2.2629959344863892, 2.26762273311615, 2.2401501417160032, 2.279429030418396, 2.2689386367797852, 2.281562256813049, 2.2553118228912354, 2.2654780387878417, 2.263076639175415, 2.2641971111297607, 2.2743114471435546, 2.2699390649795532, 2.271465611457825, 2.2663463592529296, 2.244280529022217, 2.2946118116378784, 2.276123118400574, 2.263482594490051, 2.222510290145874, 2.282894158363342, 2.265314745903015, 2.2902104377746584, 2.2616169452667236, 2.274468207359314, 2.2133959531784058, 2.2621124267578123]\n",
      " Average accuracies :  [0.135, 0.19, 0.18, 0.145, 0.205, 0.14, 0.17166666666666666, 0.14833333333333334, 0.145, 0.2, 0.14666666666666667, 0.15, 0.11333333333333333, 0.19833333333333333, 0.14333333333333334, 0.155, 0.14666666666666667, 0.18, 0.17666666666666667, 0.14666666666666667, 0.14166666666666666, 0.14833333333333334, 0.17666666666666667, 0.205, 0.13333333333333333, 0.13333333333333333, 0.20166666666666666, 0.18833333333333332, 0.145, 0.18666666666666668, 0.15166666666666667, 0.14833333333333334, 0.08333333333333333, 0.14833333333333334, 0.14833333333333334, 0.15666666666666668, 0.16, 0.17, 0.19833333333333333, 0.19333333333333333, 0.15, 0.15333333333333332, 0.20833333333333334, 0.145, 0.11333333333333333, 0.18333333333333332, 0.14166666666666666, 0.175, 0.12166666666666667, 0.15, 0.115, 0.15, 0.13333333333333333, 0.18666666666666668, 0.16666666666666666, 0.17, 0.16, 0.14333333333333334, 0.16166666666666665, 0.18666666666666668, 0.13666666666666666, 0.16333333333333333, 0.19, 0.16833333333333333, 0.17833333333333334, 0.17166666666666666, 0.155, 0.12833333333333333, 0.15166666666666667, 0.14833333333333334, 0.13333333333333333, 0.15833333333333333, 0.14833333333333334, 0.17333333333333334, 0.17333333333333334, 0.15666666666666668, 0.2, 0.14833333333333334, 0.19166666666666668, 0.13666666666666666, 0.16833333333333333, 0.17333333333333334, 0.18833333333333332, 0.15, 0.15833333333333333, 0.16666666666666666, 0.15833333333333333, 0.145, 0.20333333333333334, 0.10333333333333333, 0.11833333333333333, 0.19, 0.22, 0.15166666666666667, 0.20333333333333334, 0.13, 0.15833333333333333, 0.18666666666666668, 0.23833333333333334, 0.14166666666666666]\n",
      "Epoch  8  ...\n",
      " Average losses :  [2.271939730644226, 2.2699700593948364, 2.2708939790725706, 2.2730886459350588, 2.2520323038101195, 2.2816620588302614, 2.2487907648086547, 2.2660151720046997, 2.27291316986084, 2.2301310300827026, 2.27747220993042, 2.272586226463318, 2.2745898485183718, 2.2398260593414308, 2.2830793142318724, 2.2684787034988405, 2.2661414623260496, 2.2299755096435545, 2.2600512742996215, 2.282040596008301, 2.262525701522827, 2.2696775436401366, 2.274152684211731, 2.2452908515930177, 2.290959882736206, 2.2716664552688597, 2.261981201171875, 2.2525052785873414, 2.269368529319763, 2.237971568107605, 2.249993419647217, 2.2664310216903685, 2.2734526872634886, 2.2824040412902833, 2.255398988723755, 2.265607166290283, 2.2482503175735475, 2.255490303039551, 2.258305859565735, 2.226158618927002, 2.2719496488571167, 2.2588699579238893, 2.217690277099609, 2.2777613401412964, 2.271714997291565, 2.256037163734436, 2.2657202005386354, 2.254274845123291, 2.2901387453079223, 2.276429557800293, 2.288304924964905, 2.2691596508026124, 2.2730068445205687, 2.242675852775574, 2.256115508079529, 2.2766934633255005, 2.2576079845428465, 2.267325019836426, 2.236078906059265, 2.2388895988464355, 2.276709794998169, 2.273780632019043, 2.25503089427948, 2.2700825452804567, 2.2460617303848265, 2.2652248620986937, 2.26783549785614, 2.267597961425781, 2.2576167345047, 2.257042169570923, 2.2865258693695067, 2.2801828622817992, 2.269891786575317, 2.271812915802002, 2.253352236747742, 2.262817549705505, 2.232907795906067, 2.2728750944137572, 2.2662630319595336, 2.277160406112671, 2.231270098686218, 2.2539634227752687, 2.2481919527053833, 2.26594934463501, 2.267891502380371, 2.2582569122314453, 2.25924129486084, 2.2537155628204344, 2.2130739450454713, 2.2795560121536256, 2.26289849281311, 2.255165123939514, 2.2183367013931274, 2.2801031827926637, 2.2489130020141603, 2.278589105606079, 2.2646819353103638, 2.2787189722061156, 2.1949171304702757, 2.24708354473114]\n",
      " Average accuracies :  [0.145, 0.185, 0.15833333333333333, 0.14, 0.235, 0.17333333333333334, 0.17, 0.18, 0.145, 0.21666666666666667, 0.15333333333333332, 0.16, 0.14333333333333334, 0.21333333333333335, 0.14333333333333334, 0.18333333333333332, 0.18, 0.22, 0.155, 0.145, 0.185, 0.15166666666666667, 0.18, 0.20166666666666666, 0.16, 0.13166666666666665, 0.19833333333333333, 0.21666666666666667, 0.175, 0.175, 0.17833333333333334, 0.19333333333333333, 0.11666666666666667, 0.135, 0.135, 0.15833333333333333, 0.185, 0.18666666666666668, 0.20333333333333334, 0.19, 0.15333333333333332, 0.155, 0.25, 0.18333333333333332, 0.12666666666666668, 0.19666666666666666, 0.15, 0.19, 0.14166666666666666, 0.16333333333333333, 0.14166666666666666, 0.145, 0.14833333333333334, 0.22, 0.18833333333333332, 0.14166666666666666, 0.18333333333333332, 0.17, 0.18333333333333332, 0.22333333333333333, 0.17666666666666667, 0.16666666666666666, 0.17166666666666666, 0.17166666666666666, 0.21333333333333335, 0.17, 0.18666666666666668, 0.14833333333333334, 0.16333333333333333, 0.18, 0.115, 0.14, 0.18666666666666668, 0.14833333333333334, 0.19, 0.14666666666666667, 0.19666666666666666, 0.165, 0.17333333333333334, 0.14833333333333334, 0.185, 0.195, 0.19833333333333333, 0.155, 0.18166666666666667, 0.17833333333333334, 0.17833333333333334, 0.18, 0.2633333333333333, 0.14, 0.17833333333333334, 0.21166666666666667, 0.22666666666666666, 0.12666666666666668, 0.20833333333333334, 0.15833333333333333, 0.18833333333333332, 0.17166666666666666, 0.2633333333333333, 0.165]\n",
      "Epoch  9  ...\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "teacher_train_history = {'avg_losses':{}, 'avg_accuracies':{}}\n",
    "for e in range(epochs):\n",
    "    print(\"Epoch \", (e+1), \" ...\")\n",
    "    \n",
    "    avgloss = []\n",
    "    avgacc = []\n",
    "    \n",
    "    for i in range(num_teacher):\n",
    "        counter = 0\n",
    "        total_loss = 0\n",
    "        acc_count = 0\n",
    "        \n",
    "        model = teachers[i]\n",
    "        dataloader = teacherloader[i]\n",
    "        optimizer = teacheroptim[i]\n",
    "        \n",
    "        for images, labels in dataloader:\n",
    "            counter += images.size(0)\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            logps = model(images)\n",
    "            preds = torch.argmax(torch.exp(logps), dim=1)\n",
    "            \n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            acc_count += (preds == labels).sum().item()\n",
    "        \n",
    "        avgloss.append(total_loss/counter)\n",
    "        avgacc.append(acc_count/counter)\n",
    "    \n",
    "    print(\" Average losses : \", [avgl for avgl in avgloss])\n",
    "    print(\" Average accuracies : \", [avga for avga in avgacc])\n",
    "    teacher_train_history['avg_losses'][e] = avgloss\n",
    "    teacher_train_history['avg_accuracies'][e] = avgacc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, epochs+1),[np.mean(teacher_train_history['avg_losses'][x]) for x in teacher_train_history['avg_losses']], label=\"Training loss\")\n",
    "plt.plot(range(1, epochs+1),[np.mean(teacher_train_history['avg_accuracies'][x]) for x in teacher_train_history['avg_accuracies']], label=\"Training Accuracies\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in teachers:\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "total_loss = 0\n",
    "acc_count = 0\n",
    "\n",
    "pred_list = 0\n",
    "label_list = 0\n",
    "\n",
    "for images, labels in testloader:    \n",
    "    \n",
    "    label_list.append(labels)\n",
    "    images, labels = images.to(device), images.to(device)\n",
    "    \n",
    "    temp_pred = []\n",
    "    with torch.no_grad:\n",
    "         for model in teachers:                 \n",
    "            counter += images.size(0)\n",
    "            \n",
    "            logps = model(images)\n",
    "            preds = (torch.exp(logps)).argmax(dim=1)\n",
    "            pred_list.append(preds.cpu())\n",
    "            \n",
    "            loss = criterion(logps, labels)\n",
    "            total_loss += loss.item()\n",
    "            acc_count += (preds==labels).sum().item()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
